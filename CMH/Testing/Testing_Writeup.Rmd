---
title: "Early warning signals derived from COVID-19 testing data"
author: "Christopher M. Hoover, Joshua Schwab, Maya Peterson, Mark van der Laan, others"
csl: "plos.csl"
bibliography: "c19ref.bib"
output: 
  pdf_document: 
    keep_tex: true
  word_document:
    reference_docx: "../../../choover_word_styles.docx"  
geometry: margin=2cm 
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,
                      message = FALSE,
                      warning = FALSE)

require(adaptivetau)
require(parallel)
require(deSolve)
require(dagitty)
require(EpiEstim)
require(tidyverse)

```

## Abstract  
COVID19 testing data is essential to monitor the status of ongoing epidemics across the U.S. and the world. Because of the high rate of asymptomatic and mildly symptomatic cases that contribute to transmission, widespread testing and subsequent contact tracing and isolation are necessary to reduce epidemic spread. The effective reproductive rate, $\mathcal{R}_e$, is a simple measure of transmission interpreted as the expected number of new infections arising from a single infection at a given time, that can be used to monitor the status of an outbreak. Here we discuss estimation of $\mathcal{R}_e$ from currently available testing data and proprose methods to correct for inherent biases that currently limit the utility of testing as a reliable indicator of the status of the COVID19 pandemic.  

# TODO:  
* Update DAG based on Maya and Mark email chain, incorporate time ordering  
  - How does $\mathbb{E}(Y(t))/\mathbb{E}(Y(t-7))$ (or something similar) relate to $\mathcal{R}_e$?  
* Decide on data generating mechanism (ABM?)  
* **With line list data** adjust testing for demographics, zip code, SES, age  
* Estimate $\mathcal{R}_e$ from testing data adjusted for underreporting using Hospitalizations/Deaths data ([LSHTM method](https://cmmid.github.io/topics/covid19/global_cfr_estimates.html))  

# Background   
## COVID19  
Areas across the United States and the world are beginning to reopen following the unprecedented pandemic caused by the emergence of SARS-CoV2. Widespread availability of testing for active and past infections remains a critical component of the ongoing response to the COVID19 pandemic...  
 
## Testing   
* Background on types of tests  
* What tests are actually doing (e.g. distingiush PCR = active infections, antibody = past infections)  
  - Sensitivity issues  

### Testing can be earliest indicator of rising infections if conducted/analyzed appropriately  
Hospitalizations and deaths are more what we're worried about, but these are preceded in time by increase in cases. Since tests can detect infection before these more severe outcomes, they can be an earlier indicator of increases in transmission. A useful summary statistic to estimate the current status of an outbreak is $\mathcal{R}_e$, the expected number of additional cases caused by a single case at any time during the outbreak [@gosticPracticalConsiderationsMeasuring2020]. 

### Testing cannot currently be used to reliably estimate $\mathcal{R}_e$ because of bias due to variability in test-seeking behaviors, test availability (geographically, socioeconomically, etc.)  
Testing can be used in either passive or active surveillance to monitor the status of ongoing outbreaks. Especially early in the outbreak when testing was not widely available, the set of individuals allowed (wc?) to be tested was restricted. To date, most COVID19 testing data has been passively collected: those with suspected COVID19 exposure or symptoms seek out testing from a healthcare provider, rather than actively being pursued to be tested in a more systematic fashion, e.g. as part of a representative cohort of the population of interest. This introduces considerable bias into epidemiological estimates derived from the testing data, such as $\mathcal{R}_e$. [Review CITEs on passive surveillance and bias] The number of tests available, test-seeking behaviors of different populations/individuals, and [something else] all influence the number of positive tests and the positive test percent in a given location and time (Figure 1, W2; **Maybe could add $\mathcal{R}_e$ to the DAG as a function of $Y$?**). 

Crude metrics from testing data such as the number of positive tests reported or the percent of tests conducted that are positive have been/are being used to monitor the status of outbreaks across the US/world. However, such metrics are heavily biased due to reasons outlines above, and may be flawed representations of true underlying infection dynamics such as $\mathcal{R}_e$ [**Think this sentence/point is really important and could use some work**]. Here we propose/review methods for correcting for these underlying biases in testing data, discuss their pros and cons, and evaluate their ability to a) estimate $\mathcal{R}_e$ in real time and b) predict a future increase in hospitalizations that will overwhelm capacity. We conclude by proposing methods to generate unbiased testing data prospectively using adaptive design (active surveillance, embedding prospective cohorts within passive testing, all/none of the above?) and [hopefully] show that these methods outperform those currently available that rely on inherent flaws in currently available testing data. 

```{r dag, fig.cap = "TODO: Make this longitudinal? Data generating process for COVID19 testing data where W1 is demographic covariates (age, race, SES), W2 is risk covariates (symptoms, contacts), Y is SARS-CoV2 infection status, delta is testing status. The observed data $O$ consists of ($W_1, delta, dW2, dY$), but conditioing on $W_2$ is necessary to identify $E(Y)$. "}
dag <- dagitty("dag {
W1 -> W2
W1 -> Y
W2 -> Y
W2 -> dW2
W2 -> delta
Y -> dY
dW2 -> dY
delta -> dW2
delta -> dY
}")

coordinates( dag ) <-
  list( x=c(W1=0, W2=0, delta=1, Y = 2, dW2=2, dY=3),
        y=c(W1=-3, W2=-2, delta=-1, Y = -2.5, dW2=-2, dY=-2) )
plot( dag )
```

# Correcting for bias/Accurate estimation of $E(Y)$/Adjusting for $W2$   
```{r tab1}
method1 <- list("Method" = "Number of positive tests",
                "Pros" = "real-time, simple, no analysis required",
                "Cons" = "Heavily biased by number of tests conducted, test-seeking behaviors, etc",
                "Reference" = "")

method2 <- list("Method" = "Percent of tests conducted that are positive",
                "Pros" = "Real-time, simple, removes bias from number of tests conducted",
                "Cons" = "Heavily biased by test-seeking behaviors, etc.",
                "Reference" = "")

method3 <- list("Method" = "Adjustment from additional epidemiological data",
                "Pros" = "Removes bias associated with test-seeking",
                "Cons" = "Delay between infection and hospitalization/death means unable to estimate in real-time",
                "Reference" = "LSHTM")

method4 <- list("Method" = "Adjustment from additional demographic/survey? data",
                "Pros" = "Simple and straightforward",
                "Cons" = "Does not adequately control for confounding by W2, requires linelist testing data",
                "Reference" = "")

method5 <- list("Method" = "Fitting dynamic models",
                "Pros" = "Real-time, draws on multiple data sources to control for biases",
                "Cons" = "Identifiable?, complex and computationally intensive",
                "Reference" = "")


tab1_df <- data.frame(matrix(unlist(list(method1, method2, method3, method4, method5)), 
                             ncol=4, byrow=T))

colnames(tab1_df) <- names(method1)

tab1_df %>% 
  knitr::kable(format = "latex", booktabs = TRUE,
               caption = "Methods to estimate E(Y)") %>% 
  kableExtra::kable_styling(latex_options = "scale_down")
```

## Approaches  
### Data-generating process  
Needs to:  

* Accurately represent influence of W1 and W2 on transmission  
* Accurately represent influence of W1 and W2 on testing (both simulated and observed)  
* Allow easy manipulation/implementation of changes in $\mathcal{R}_e$  
* Track infection and testing status across different (SES, race, demographic, occupational?) groups  

#### Candidates:  
* Agent-based model  
* Branching-process model with network influence  
* Something simpler may be adequate for the point that testing isn't great and could be improved  

### Estimation from raw testing data  
Either number of positive tests or pct positive tests

### Adjustment from additional data sources (demographic [Age, Race, Zip, SES] and/or epidemiologic [hospitalizations and deaths])  

#### LSHTM method (Case-fatality ratio adjustment?)  
* Time-delay limits utility  
* See [this LSHTM report](https://cmmid.github.io/topics/covid19/global_cfr_estimates.html) for one method that seems to be widely accepted  
* I worked briefly on trying to derive a max likelihood estimate of COVID19 cases on day t from hospitalizations and deaths, but got stuck on right censoring. Could revive that effort though  

### Adjustment built into model fitting  
Big question: How inherently different is this really from methods above? Just a combination of them? 

#### Approach Chris has been working on   
* Still relies on additional data sources for fitting    
* Projections require assumptions of number of tests, bias in testing in the future  




# Improving testing (Is this another paper even??)   

* What additional data can be reported to improve epi estimates (Symptom status, age, etc.)   
* Can additional data be collected in order to improve the utility of available testing resources  
  - Intuition is that smart reallocation of testing to do some active surveillance will improve estimation even more than just doing more tests, which I think could/should be one of the main messages  
  - Could maybe start with data from the Mission Study, use it to derive age/race/income? adjusted rates for all of SF, compare to testing data reported for all of SF county at the same time. Could provide an initial estimate of testing bias. Would be even better if we could do record linkage between Mission Study and other testing data  
  
  
  
# Potential Figures  
```{r SF_data}
#Downloads data into dataframe called latest_covid_CA
source("../Get_COVID_Cal_counties_latest.R")

SF.pop <- 883305

sf_hosp <- read.csv(url("https://data.sfgov.org/resource/nxjg-bhem.csv")) %>% 
  mutate(Date = as.Date(reportdate),
         type = ifelse(dphcategory == "ICU", "ICU", "HOSP"),
         conf = ifelse(covidstatus == "PUI", "PUI", "CONF"),
         hosp_stat = paste(type, conf, sep = "_")) %>% 
  pivot_wider(names_from = hosp_stat,
              values_from = patientcount) %>%
  group_by(Date) %>% 
  summarise(ICU_PUI = sum(ICU_PUI, na.rm = T),
            ICU_CONF = sum(ICU_CONF, na.rm = T),
            HOSP_PUI = sum(HOSP_PUI, na.rm = T),
            HOSP_CONF = sum(HOSP_CONF, na.rm = T)) %>% 
  arrange(Date) %>% 
  mutate(HOSP_tot = ICU_CONF + HOSP_CONF,
         HOSP_max = ICU_CONF + HOSP_CONF + ICU_PUI + HOSP_PUI,
         cumICUconf = cumsum(ICU_CONF),
         cumICUpui = cumsum(ICU_PUI),
         cumHOSPconf = cumsum(HOSP_CONF),
         cumHOSPpui = cumsum(HOSP_PUI))

sf_case <- read.csv(url("https://data.sfgov.org/resource/tvq9-ec9w.csv")) %>% 
  mutate(Date = as.Date(specimen_collection_date)) %>% 
  pivot_wider(names_from = case_disposition,
              values_from = case_count) %>% 
  group_by(Date) %>% 
  summarise(Cases = sum(Confirmed, na.rm = T),
            Deaths = sum(Death, na.rm = T)) %>% 
  arrange(Date) %>% 
  mutate(cum_case = cumsum(Cases),
         cum_death = cumsum(Deaths))

sf_test <- read.csv(url("https://data.sfgov.org/resource/nfpa-mg4g.csv")) %>% 
  mutate(Date = as.Date(specimen_collection_date)) %>% 
  arrange(Date) %>% 
  mutate(cum_tests = cumsum(tests),
         cum_pos = cumsum(pos))

sf_all <- sf_test %>% 
  dplyr::select(Date, tests, pos, neg, pct, indeterminate, cum_tests, cum_pos) %>%
  full_join(sf_case, by = "Date") %>% 
  full_join(sf_hosp, by = "Date") %>% 
  mutate(time = as.integer(Date - as.Date("2020-02-29"))) %>% 
  filter(time >0)

```

## SF Testing  
```{r sf_test_plot}
sf_test_plot_df <- sf_test %>% 
  mutate(tests_10k = (tests/SF.pop)*10000,
         tests_7dayavg = zoo::rollmean(tests,7,na.pad = T,align = "right"),
         tests10k_7dayavg = zoo::rollmean(tests_10k,7,na.pad = T,align = "right"),
         pct_7day_avg = zoo::rollmean(pct*100,7,na.pad = T,align = "right")) %>%
  dplyr::select(Date, tests10k_7dayavg, pct_7day_avg) %>% 
  pivot_longer(-Date, names_to = "Test", values_to = "Num")

test_plot <- sf_test_plot_df %>% 
  ggplot() +
    geom_line(aes(x = Date, y = Num, col = Test),
              size = 1.1) +
    theme_bw() +
    scale_color_manual(values = c("purple", "gold"),
                       labels = c("% Positive",
                                  "Tests\nconducted/10k")) +
    scale_x_date(date_labels = "%m/%d", 
               date_breaks = "7 day") +
    theme(axis.title = element_text(size = 14,
                                    face = "bold"),
          axis.text = element_text(size = 12),
          axis.text.x = element_text(angle = 45,
                                     hjust = 1)) +
    labs(x = "Date",
         y = "Tests and %Positive (7-day average)",
         col = "",
         title = "COVID19 testing in SF")

test_plot

```

## $\mathcal{R}_e$ estimation  
Cori et al method [@coriNewFrameworkSoftware2013; @gosticPracticalConsiderationsMeasuring2020]

```{r cori_Re}
# Get times for estimation
sf_inc <- as.numeric(sf_all %>% filter(Date >as.Date("2020-03-05")) %>% pull(pos) %>% na.omit())
window = 7
ts <- 2:(length(sf_inc)-(window+1))
te <- 2:(length(sf_inc)-(window+1))+window

R_config <- EpiEstim::make_config(t_start = ts,
                                  t_end = te,
                                  mean_si = 4.5,
                                  std_si = 1)

SF_cori_R <- EpiEstim::estimate_R(incid = sf_inc,
                                  method = "parametric_si",
                                  config = R_config)

SF_cori_R$R %>%
  mutate(Date = as.Date("2020-03-05")+t_start) %>% 
  ggplot() +
    theme_bw() +
    geom_col(data = sf_case,
             aes(x = Date, y = (Cases/9e5)*1e5),
             fill = "blue", col = "darkblue", alpha = 0.3) +
    geom_line(aes(x = Date, y = `Median(R)`),
              size = 1.2, col = "red") +
    geom_ribbon(aes(x = Date, y = `Median(R)`,
                   ymin = `Quantile.0.025(R)`,
                   ymax = `Quantile.0.975(R)`),
                fill = "red", alpha = 0.4) +
    scale_x_date(date_labels = "%m/%d", 
               date_breaks = "7 day") +
    theme(axis.title = element_text(size = 14,
                                    face = "bold"),
          axis.text = element_text(size = 12),
          axis.text.x = element_text(angle = 45,
                                     hjust = 1)) +
    scale_y_continuous(breaks = c(1,3,5,7)) +
    labs(x = "Date",
         y = expression(R[e]~estimate),
         title = "Cori et al estimate of R through time from SF testing data")

```  
  
# References  
