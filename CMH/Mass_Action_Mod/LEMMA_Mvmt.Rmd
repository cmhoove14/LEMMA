---
title: "LEMMA_Mvmt_Force"
author: "Chris Hoover"
date: "5/28/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,
                      fig.height = 6, 
                      fig.width = 8)

require(deSolve)
require(ggplot2)
require(coda)
require(tidyverse)

```

# Purpose  
Use movement data incorporated into a dynamic model of COVID transmission via a forcing function to fit early-stage outbreak dynamics and forecast transmission into the future using movement projections.

# Movement Data  
## Descartes Labs  
Technical report [here](https://arxiv.org/pdf/2003.14228.pdf). Data represents "the median of the max-distance mobility for all samples in the specified region" derived from anonymized mobile phone data.
```{r descartes, fig.align='left'}
descartes <- read.csv(url("https://raw.githubusercontent.com/descarteslabs/DL-COVID-19/master/DL-us-mobility-daterow.csv"))

descartes_sf <- descartes %>% 
  filter(admin1 == "California" & admin2 == "San Francisco County") %>% 
  mutate(rel_m = m50/max(m50))

t0 <- as.Date("2020-02-16")
t.end <- as.Date(descartes_sf$date[nrow(descartes_sf)])

descartes_sf %>% 
  ggplot(aes(x = as.Date(date), y = m50)) + 
    geom_line() +
    theme_bw() +
    scale_x_date(date_labels = "%m/%d", 
               date_breaks = "7 day") +
    theme(axis.title = element_text(size = 14,
                                    face = "bold"),
          axis.text = element_text(size = 12),
          axis.text.x = element_text(angle = 45,
                                     hjust = 1)) +
    labs(x = "Date",
         y = "Relative Movement Index",
         title = "Descartes Movement for San Francisco County")
```

# Epi Data  
```{r sf_epi_data}
# Case and hosptialization data for SF
sf_hosp <- read.csv(url("https://data.sfgov.org/resource/nxjg-bhem.csv")) %>% 
  mutate(Date = as.Date(reportdate),
         type = ifelse(dphcategory == "ICU", "ICU", "HOSP"),
         conf = ifelse(covidstatus == "PUI", "PUI", "CONF"),
         hosp_stat = paste(type, conf, sep = "_")) %>% 
  pivot_wider(names_from = hosp_stat,
              values_from = patientcount) %>%
  group_by(Date) %>% 
  summarise(ICU_PUI = sum(ICU_PUI, na.rm = T),
            ICU_CONF = sum(ICU_CONF, na.rm = T),
            HOSP_PUI = sum(HOSP_PUI, na.rm = T),
            HOSP_CONF = sum(HOSP_CONF, na.rm = T)) %>% 
  arrange(Date) %>% 
  mutate(HOSP_tot = ICU_CONF + HOSP_CONF,
         HOSP_max = ICU_CONF + HOSP_CONF + ICU_PUI + HOSP_PUI,
         cumICUconf = cumsum(ICU_CONF),
         cumICUpui = cumsum(ICU_PUI),
         cumHOSPconf = cumsum(HOSP_CONF),
         cumHOSPpui = cumsum(HOSP_PUI))

sf_case <- read.csv(url("https://data.sfgov.org/resource/tvq9-ec9w.csv")) %>% 
  mutate(Date = as.Date(date)) %>% 
  pivot_wider(names_from = case_disposition,
              values_from = case_count) %>% 
  group_by(Date) %>% 
  summarise(Cases = sum(Confirmed, na.rm = T),
            Deaths = sum(Death, na.rm = T)) %>% 
  arrange(Date) %>% 
  mutate(cum_case = cumsum(Cases),
         cum_death = cumsum(Deaths))

sf_test <- read.csv(url("https://data.sfgov.org/resource/nfpa-mg4g.csv")) %>% 
  mutate(Date = as.Date(result_date)) %>% 
  arrange(Date) %>% 
  mutate(cum_tests = cumsum(tests),
         cum_pos = cumsum(pos))

sf_all <- sf_test %>% 
  dplyr::select(Date, tests, pos, neg, pct, indeterminate, cum_tests, cum_pos) %>%
  full_join(sf_case, by = "Date") %>% 
  full_join(sf_hosp, by = "Date")
```

```{r case_plot}
case_plot <- sf_case %>% 
  ggplot() +
    geom_point(aes(x = Date, y = cum_case),
               pch = 16, col = "coral") +
    theme_bw() +
    scale_x_date(date_labels = "%m/%d", 
               date_breaks = "7 day") +
    theme(axis.title = element_text(size = 14,
                                    face = "bold"),
          axis.text = element_text(size = 12),
          axis.text.x = element_text(angle = 45,
                                     hjust = 1)) +
    labs(x = "Date",
         y = "Cumulative cases",
         title = "Confirmed Cases in San Francisco County")
  
case_plot

```

```{r hosp_plot}
# Case and hosptialization data for SF
hosp_plot <- sf_hosp %>% 
  ggplot() +
    geom_point(aes(x = Date, y = HOSP_tot),
               pch = 17, col = "darkblue") +
    theme_bw() +
    scale_x_date(date_labels = "%m/%d", 
               date_breaks = "7 day") +
    theme(axis.title = element_text(size = 14,
                                    face = "bold"),
          axis.text = element_text(size = 12),
          axis.text.x = element_text(angle = 45,
                                     hjust = 1)) +
    labs(x = "Date",
         y = "Total hospitalizations",
         title = "Hospitalizations in San Francisco County")

hosp_plot
```

```{r mort_plot}
mort_plot <- sf_case %>% 
  ggplot() +
    geom_point(aes(x = Date, y = cum_death),
               pch = 18, col = "darkred") +
    theme_bw() +
    scale_x_date(date_labels = "%m/%d", 
               date_breaks = "7 day") +
    theme(axis.title = element_text(size = 14,
                                    face = "bold"),
          axis.text = element_text(size = 12),
          axis.text.x = element_text(angle = 45,
                                     hjust = 1)) +
    labs(x = "Date",
         y = "Cumulative deaths",
         title = "COVID Deaths in San Francisco County")

mort_plot

```


# Model  
We use a slight tweak to LEMMA to add an explicit deaths compartment in order to fit to deaths data in addition to hospitalizations  

\begin{align*}
\dot{S}&=-\beta S(I_R+I_H)/N \\
\dot{E}&=\beta S(I_R+I_H)/N-\sigma E \\
\dot{I_R}&=\sigma(1-\alpha) E-\gamma_R I_R \\
\dot{I_H}&=\sigma\alpha E-\rho I_H \\
\dot{H}&=\rho I_H-\gamma_H H \\
\dot{D}&=\gamma_H\mu H \\
\dot{R}&=\gamma_R I_R \gamma_H(1-\mu)H\\
\end{align*}

```{r mod_prep}
#source("COVID_ODE.R")

pop.size <- 883305
t.sim <- as.numeric(t.end - t0)

# Was having trouble fitting model with t0 as march 1st, not enough time for infection to build up before movement tanks, so adding some time to ramp up

set.seed(430)
t.pad <- as.numeric(t.sim - (t.end - as.Date(descartes_sf$date[1])))
m.pad <- mean(descartes_sf$m50[1:10]) + rnorm(t.pad, 0, 0.5)

descartes_force <- approxfun(as.data.frame(list(times = 1:t.sim,
                                                move = c(m.pad, descartes_sf$m50))),
                             rule = 2)

#Starting covid parameters
lemma_pars <- list(N = pop.size,
                   t.sim = t.sim,
                   E.start = 2,
                   beta = 0.1,
                   cr = 1,
                   ch = 1,
                   sigma = 1/4,
                   alpha = 0.05,
                   rho = 1/4,
                   gam_r = 1/5,
                   gam_h = 1/12,
                   mu = 0.2)

lemma_pars <- as.list(log(unlist(lemma_pars)))

```

```{r par_table, dev="tikz" }
tab1 <- data.frame(val = as.character(round(exp(as.numeric(lemma_pars)), 3)), 
                   des = c("population size",
                           "time to run simulation",
                           "starting number of exposed",
                           "transmission rate",
                           "Relative contact rate between S and Ir",
                           "Relative contact rate between S and Ih",
                           "1/serial interval",
                           "proportion severely symptomatic (will be hospitalized)",
                           "time between symptom onset and hospitalization",
                           "1/time to recovery (non-infectiousness) for mildly symptomatic",
                           "1/time hospitalized",
                           "proportion of hospitalized cases who die"))

rownames(tab1) <- c("$N$", "t.sim", "$E_0$",  "$\\beta$","$c_r$","$c_h$",
                    "$\\sigma$","$\\alpha$", "$\\rho$", 
                    "$\\gamma_r$","$\\gamma_h$","$\\mu$")

knitr::kable(tab1, row.names = TRUE, 
             col.names = c("Value", "Definition"), 
             format = "latex", escape = FALSE, 
             caption = "Parameter values and descriptions used in the model")
```

```{r mod_odes}
lemma_odes = function(t, n, p) { 

  # States
    S = n[1]
    E = n[2]
    Ir = n[3]
    Ih = n[4]
    H = n[5]
    D = n[6]
    R = n[7]
  
  # Parameters
    N = exp(p[['N']])             #population size
    beta = exp(p[['beta']])       #transmission rate
    cr = exp(p[['cr']])           #Relative contact rate between S and Ir
    ch = exp(p[['ch']])           #Relative contact rate between S and Ih
    sigma = exp(p[['sigma']])     #1/serial interval
    alpha = exp(p[['alpha']])     #proportion severely symptomatic
    rho = exp(p[['rho']])         #1/time between symptom onset and hospitalization
    gam_r = exp(p[['gam_r']])     #1/time to recovery (non-infectiousness) for mild/asymptomatic
    gam_h = exp(p[['gam_h']])     #1/time to removed (recovered or deceased) for hospitalized
    mu = exp(p[['mu']])           #proportion of hospitalized cases who die

  #Movement forcing function
    m = descartes_force(t)
  
  # Model equations
    dSdt = -S*beta*m*(Ir*cr+Ih*ch)/N
    
    dEdt = S*beta*m*(Ir*cr+Ih*ch)/N - E*sigma
    
    dIrdt = E*(1-alpha)*sigma - Ir*gam_r
    
    dIhdt = E*alpha*sigma - Ih*rho

    dHdt = Ih*rho - H*gam_h
    
    dDdt = H*mu*gam_h
    
    dRdt = Ir*gam_r+Ih*gam_h*(1-mu)

    return(list(c(dSdt, dEdt, dIrdt, dIhdt, dHdt, dDdt, dRdt)))
    
} 
```

```{r point_fit}
#Function to return "fit" from input parameters and data
  lemma_fit <- function(fit.pars, all.pars, fit_data) {
    use.pars <- all.pars
    par.fit.index <- which(names(all.pars) %in% names(fit.pars))
    
    for(p in 1:length(par.fit.index)){
      use.pars[[par.fit.index[p]]] <- fit.pars[[p]]
    }

    # initial number of exposed as parameter
    init <- c(S = exp(use.pars[["N"]]) - exp(use.pars[["E.start"]]),
              E = exp(use.pars[["E.start"]]),
              Ir = 0,
              Ih = 0,
              H = 0,
              D = 0,
              R = 0)
    
    # Run the model with input parameters to generate predicted quantities
    mod.run <- as.data.frame(ode(init, 1:exp(use.pars[["t.sim"]]), lemma_odes, use.pars)) %>% 
      mutate(Date = as.Date(t0+(time-1)))
    
    # Join simulated and observed data
    mod.obs.dat <- mod.run %>% 
      full_join(fit_data, by = "Date")
    
    ## Calculate the log likelihood (logLike) of the data given theta (parameter set)
  	hosp.llik <- dnorm(mod.obs.dat$H, mod.obs.dat$HOSP_CONF, 2, log = T)
  	mort.llik <- dnorm(mod.obs.dat$D, mod.obs.dat$cum_death, 1, log = T)

    post.llik <- sum(hosp.llik, mort.llik, na.rm = T)
    
    #print(c(use.pars[["E.start"]], use.pars[["beta"]], post.llik))
    
  	return(post.llik)
  }

lemma_sweeps <- expand.grid(E.start = log(c(1:10)),
                            beta = log(seq(1e-3, 0.5, by = 5e-3)))

require(parallel)
opclust <- makeCluster(detectCores()-1)         # Make cluster
clusterExport(opclust, c("lemma_sweeps",
                         "lemma_pars", 
                         "lemma_fit",
                         "sf_all",
                         "lemma_odes",
                         "descartes_force",
                         "t0"))         # Export objects to cluster

clusterEvalQ(opclust, {
  library(deSolve)
  library(tidyverse)
})

lemma_fits <- parApply(opclust, lemma_sweeps, 1, function(x){
  lemma_fit(as.list(x), lemma_pars, sf_all)
})

stopCluster(opclust)

lemma_rslts <- cbind(lemma_sweeps, lemma_fits)
```

```{r point_fit_plot}
best.pars <- lemma_pars
best.pars[["beta"]] <- lemma_rslts$beta[which(lemma_fits == max(lemma_fits))]
best.pars[["E.start"]] <- lemma_rslts$E.start[which(lemma_fits == max(lemma_fits))]

  init <- c(S = exp(best.pars[["N"]]) - exp(best.pars[["E.start"]]),
            E = exp(best.pars[["E.start"]]),
            Ir = 0,
            Ih = 0,
            H = 0,
            D = 0,
            R = 0)


best.sim <- as.data.frame(ode(init, 
                              1:exp(best.pars[["t.sim"]]), 
                              lemma_odes, 
                              best.pars)) %>% 
  mutate(Date = as.Date(t0+time)) 

ggplot() +
  theme_bw() +
  theme(axis.title = element_text(size = 14,
                                  face = "bold"),
        axis.text = element_text(size = 12),
        axis.text.x = element_text(angle = 45,
                                   hjust = 1)) +
  geom_line(data = best.sim,
            aes(x = Date, y = H),
            col = "coral", size = 1.2) +
  geom_point(data = sf_all,
             aes(x = Date, y = HOSP_tot),
             pch = 17) +
  scale_x_date(date_labels = "%m/%d", 
               date_breaks = "7 day")

ggplot() +
  theme_bw() +
  theme(axis.title = element_text(size = 14,
                                  face = "bold"),
        axis.text = element_text(size = 12),
        axis.text.x = element_text(angle = 45,
                                   hjust = 1)) +
  geom_line(data = best.sim,
            aes(x = Date, y = D),
            col = "coral", size = 1.2) +
  geom_point(data = sf_all,
             aes(x = Date, y = cum_death),
             pch = 17) +
  scale_x_date(date_labels = "%m/%d", 
               date_breaks = "7 day")
  

```

## TODO: Two populations  
* How to divide movement/contact between the two populations?  

```{r odes_2pop}
lemma_2pop_odes = function(t, n, p) { 

  # States
    S1 = n[1]
    E1 = n[2]
    Ir1 = n[3]
    Ih1 = n[4]
    H1 = n[5]
    D1 = n[6]
    R1 = n[7]
 
    S2 = n[8]
    E2 = n[9]
    Ir2 = n[10]
    Ih2 = n[11]
    H2 = n[12]
    D2 = n[13]
    R2 = n[14]
 
  # Parameters
    N = exp(p[['N']])             #population size
    beta = exp(p[['beta']])       #transmission rate
    cr = exp(p[['cr']])           #Relative contact rate between S and Ir
    ch = exp(p[['ch']])           #Relative contact rate between S and Ih
    sigma = exp(p[['sigma']])     #1/serial interval
    alpha = exp(p[['alpha']])     #proportion severely symptomatic
    rho = exp(p[['rho']])         #1/time between symptom onset and hospitalization
    gam_r = exp(p[['gam_r']])     #1/time to recovery (non-infectiousness) for mild/asymptomatic
    gam_h = exp(p[['gam_h']])     #1/time to removed (recovered or deceased) for hospitalized
    mu = exp(p[['mu']])           #proportion of hospitalized cases who die

  #Movement forcing function
    m = descartes_force(t)
  
  # Model equations pop 1
    dS1dt = -S1*beta*m*(Ir*cr+Ih*ch)/N
    
    dE1dt = S1*beta*m*(Ir*cr+Ih*ch)/N - E*sigma
    
    dIr1dt = E*(1-alpha)*sigma - Ir*gam_r
    
    dIh1dt = E*alpha*sigma - Ih*rho

    dH1dt = Ih*rho - H*gam_h
    
    dD1dt = H*mu*gam_h
    
    dR1dt = Ir*gam_r+Ih*gam_h*(1-mu)

  # Model equations pop 2
    dS2dt = -S*beta*m*(Ir*cr+Ih*ch)/N
    
    dE2dt = S*beta*m*(Ir*cr+Ih*ch)/N - E*sigma
    
    dIr2dt = E*(1-alpha)*sigma - Ir*gam_r
    
    dIh2dt = E*alpha*sigma - Ih*rho

    dH2dt = Ih*rho - H*gam_h
    
    dD2dt = H*mu*gam_h
    
    dR2dt = Ir*gam_r+Ih*gam_h*(1-mu)
    
    
    return(list(c(dS1dt, dE1dt, dIr1dt, dIh1dt, dH1dt, dD1dt, dR1dt,
                  dS2dt, dE2dt, dIr2dt, dIh2dt, dH2dt, dD2dt, dR2dt)))
    
} 
```


```{r mcmcMH_setup}
#Function to return "fit" from input parameters and data
  lemma_mcmc_fit <- function(theta.pars, fit_data) {
    # initial number of exposed as parameter
    init <- c(S = exp(theta.pars[["N"]]) - exp(theta.pars[["E.start"]]),
              E = exp(theta.pars[["E.start"]]),
              Ir = 0,
              Ih = 0,
              H = 0,
              D = 0,
              R = 0)
    
    # Run the model with input parameters to generate predicted quantities
    mod.run <- as.data.frame(ode(init, 1:exp(theta.pars[["t.sim"]]), lemma_odes, theta.pars)) %>% 
      mutate(Date = as.Date(t0+(time-1)))
    
    # Join simulated and observed data
    mod.obs.dat <- mod.run %>% 
      full_join(fit_data, by = "Date")
    
    ## Calculate the log likelihood (logLike) of the data given theta (parameter set)
  	hosp.llik <- dnorm(mod.obs.dat$H, mod.obs.dat$HOSP_CONF, 8, log = T)
  	mort.llik <- dnorm(mod.obs.dat$D, mod.obs.dat$cum_death, 4, log = T)

    post.llik <- sum(hosp.llik, na.rm = T) + sum(mort.llik, na.rm = T)
    
  	return(post.llik)
  }

#St.devs of lemma parameters

lemma_sds <- list(N = 0,
                  t.sim = 0,
                  E.start = 2,
                  beta = 0.3,
                  cr = 0,
                  ch = 0,
                  sigma = 0,#1/4,
                  alpha = 0.1,
                  rho = 0,#1/4,
                  gam_r = 0,#1/5,
                  gam_h = 0,#1/6,
                  mu = 0.05)


## Metropolis-Hastings algorithm for searching parameter space (arbitrary
## number of parameters):

# This is a function that takes four parameters:
# 1. posterior: The posterior function: A function that accepts parameter
#    values as an argument and returns the logged value of the
#    posterior function at these values.
# 2. initTheta: The initial value of theta - the vector of parameter 
#    values.
# 3. proposalSD: The standard deviation of a Gaussian proposal
#    distribution for the Metropolis-Hastings algorithm to search
#    parameter space.
# 4. numIterations: The number of iterations to run the
#    Metropolis-Hastings algorithm for.
# The function returns a vector of samples of theta based on the accepted
# values from the Metropolis-Hastings algorithm.

mcmcMH <- function(posterior, fitData, initTheta, proposalSD, numIterations) {
  
  # Evaluate the function "posterior" at "initTheta", and assign to a
  # variable called posteriorThetaCurrent.
  posteriorThetaCurrent <- posterior(initTheta, fitData)
  
  # Initialise variables to store the current value of theta, the
  # vector of sample values, and the number of accepted proposals.
  thetaCurrent <- initTheta
  samples <- matrix(0, nrow = numIterations+1, ncol = length(unlist(initTheta))+1)
  accepted <- 0
    samples[1,] <- c(unlist(initTheta), accepted)
  
  # Run the MCMC algorithm for numIterations interations.
  for (i in 1:numIterations) {
    
    accepted <- 0
    
    # Draw a new theta from a Gaussian proposal distribution and
    # assign this to a variable called thetaProposed.
    thetaProposed <- rnorm(n = length(thetaCurrent),
                           mean = unlist(thetaCurrent), 
                           sd = unlist(proposalSD))
    
    # Assign names to the thetaProposed vector.
    names(thetaProposed) <- names(thetaCurrent)
    
    # Evaluate the log) posterior function at the proposed theta
    # value and assign to a variable called 
    # posteriorThetaProposed.
    posteriorThetaProposed <- posterior(as.list(thetaProposed), fitData)
    
    # Compute the Metropolis-Hastings (log) acceptance
    # probability and assign to a variable called
    # logAcceptance.
    logAcceptance <- posteriorThetaProposed - posteriorThetaCurrent
    
    # Draw a random number uniformly-distributed between 0 and 1
    # using "runif" and assign to a variable called randNum.
    randNum <- runif(n = 1, min = 0, max = 1)

    # Use the random number and the acceptance probability to 
    # determine if thetaProposed will be accepted.
    if (randNum < exp(logAcceptance)) {
      
      # If accepted, change the current value of theta to the
      # proposed value of theta.
      thetaCurrent <- thetaProposed
      
      # And update the current value of the posterior 
      # function.
      posteriorThetaCurrent <- posteriorThetaProposed
      
      # And update number of accepted proposals.
      accepted <- 1
    }
    
    # Add the current theta to the vector of samples.
    samples[i+1,] <- c(unlist(thetaCurrent), accepted)
    
    # Print the current state of chain and acceptance rate.
      if(i %% 100 == 0){
        cat("iteration:", i, "out of", numIterations, 
            " acceptance rate:", sum(samples[,ncol(samples)])/i, "\n")
      }
  }
  return(samples)
}

```

```{r mcmcMH_fit}
lemma_fit1 <- mcmcMH(posterior = lemma_mcmc_fit,
                       fitData = sf_all,
                       initTheta = lemma_pars,
                       proposalSD = lemma_sds,
                       1000)

# Use the package "coda" to convert the trace into this format:
  trace <- coda::mcmc(exp(lemma_fit1[-1,which(unlist(lemma_sds) != 0)]))
  colnames(trace) <- names(lemma_sds)[which(unlist(lemma_sds) != 0)]
  plot(coda::mcmc(trace))
  summary(trace)

```